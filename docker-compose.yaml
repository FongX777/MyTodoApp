# Compose file format is detected automatically

services:
  # Backend API with instrumentation (Prometheus metrics + structured logging)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    # 使用 Dockerfile 中的預設命令
    # Development: make FastAPI reloadable. In production remove command & volume.
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload --reload-dir /app/app
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@db:5432/mytodoapp
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1
      - FASTAPI_RELOAD=true
    logging:
      driver: "json-file"
      options:
        tag: "{{.Name}}"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - observability-network
    volumes:
      - ./backend/app:/app/app:rw
    depends_on:
      db:
        condition: service_healthy

# Frontend application
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3001:80"
    environment:
      - REACT_APP_API_BASE_URL=http://localhost:8000
    restart: unless-stopped
    networks:
      - observability-network
    depends_on:
      - backend
      
  # PostgreSQL database
  db:
    image: postgres:16
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=mytodoapp
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - observability-network
    volumes:
      - pg_data:/var/lib/postgresql/data/
      
  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./dev/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./dev/prometheus/rules:/etc/prometheus/rules
    networks:
      - observability-network
    depends_on:
      - backend
  
  # Grafana for metrics visualization
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - ./dev/grafana:/etc/grafana/provisioning
    networks:
      - observability-network
    depends_on:
      - prometheus
  
  # Elasticsearch for log storage and search
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    ports:
      - "9200:9200"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=true
      - "ES_JAVA_OPTS=-Xms256m -Xmx256m"
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - ELASTIC_PASSWORD=password
      - xpack.security.authc.api_key.enabled=true
      - cluster.routing.allocation.disk.threshold_enabled=false
      - cluster.routing.allocation.disk.watermark.low=95%
      - cluster.routing.allocation.disk.watermark.high=96%
      - cluster.routing.allocation.disk.watermark.flood_stage=97%
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - observability-network
    healthcheck:
      test: ["CMD", "curl", "-u", "elastic:password", "-f", "http://localhost:9200/_cat/health"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
  
  # Kibana for log visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - ELASTICSEARCH_SERVICEACCOUNTTOKEN=${KIBANA_SERVICE_TOKEN:-}
      - SERVER_NAME=kibana
      - SERVER_PUBLICBASEURL=http://localhost:5601
    networks:
      - observability-network
    depends_on:
      elasticsearch:
        condition: service_healthy

# Filebeat for shipping logs to Elasticsearch
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.8.0
    user: root
    volumes:
      - ./dev/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
      - FILEBEAT_PORT=5044
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - observability-network
  # n8n workflow automation (reuses existing Postgres DB and Redis)
  n8n:
    image: n8nio/n8n:latest
    ports:
      - "5678:5678"
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=db
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=n8n
      - DB_POSTGRESDB_USER=postgres
      - DB_POSTGRESDB_PASSWORD=postgres
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=admin
      - N8N_BASIC_AUTH_PASSWORD=admin
      - N8N_HOST=localhost
      - N8N_PORT=5678
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - NODE_ENV=production
      - N8N_COMMUNITY_PACKAGES_ALLOW_TOOL_USAGE=true
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    networks:
      - observability-network
    volumes:
      - n8n_data:/home/node/.n8n
  # Redis for n8n
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: ["redis-server","--save","60","1","--appendonly","no"]
    networks:
      - observability-network
    volumes:
      - redis_data:/data



networks:
  observability-network:
    driver: bridge

volumes:
  elasticsearch-data:
  pg_data:
  redis_data:
  n8n_data: